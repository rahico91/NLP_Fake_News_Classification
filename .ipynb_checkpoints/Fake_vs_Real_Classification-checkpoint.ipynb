{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Classification\n",
    "\n",
    "A dataset from [Real or Fake](https://www.kaggle.com/rchitic17/real-or-fake) is provided containing different news articles.\n",
    "\n",
    "We want to build a  model that can classify if a given article is considered fake or not. We will use a subset of the data for training and the remaining for testing our model.\n",
    "\n",
    "## Outline\n",
    "\n",
    "We separate the project in 3 steps:\n",
    "\n",
    "**Data Loading and Transforming:** Load the data and analyze it to obtain an accurate picture of it, its features, its values (and whether they are incomplete or wrong), its data types among others. We also do the required transformation steps.\n",
    "\n",
    "**Feature Engineering / Modeling:** Once we have the data, we create some features and then the modeling stage begins, making use of different models, we will hopefully produce a model that fits our expectations of performance. Once we have that model, a process of tuning it to the training data would be performed.\n",
    "\n",
    "**Results and Conclusions:** Finally, with our tuned model, we  predict against the test set, then we review those results against their actual values to determine the performance of the model, and finally, outline our conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rafaelhernandez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk as nl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import accuracy_score as metric_scorer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "nl.download('stopwords')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Key Values\n",
    "\n",
    "The following values are used throught the code, this cell gives a central source where they can be managed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "\n",
    "Here we load the necessary data for training and testing, review its types and print its first rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"fake_or_real_news_training.csv\")\n",
    "test = pd.read_csv(\"fake_or_real_news_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID        int64\n",
       "title    object\n",
       "text     object\n",
       "label    object\n",
       "X1       object\n",
       "X2       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label   X1   X2  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  NaN  NaN  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  NaN  NaN  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  NaN  NaN  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  NaN  NaN  \n",
       "4  It's primary day in New York and front-runners...  REAL  NaN  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U.S. Secretary of State John F. Kerry said Monday that he will stop in Paris later this week, amid criticism that no top American officials attended Sunday’s unity march against terrorism.\\n\\nKerry said he expects to arrive in Paris Thursday evening, as he heads home after a week abroad. He said he will fly to France at the conclusion of a series of meetings scheduled for Thursday in Sofia, Bulgaria. He plans to meet the next day with Foreign Minister Laurent Fabius and President Francois Hollande, then return to Washington.\\n\\nThe visit by Kerry, who has family and childhood ties to the country and speaks fluent French, could address some of the criticism that the United States snubbed France in its darkest hour in many years.\\n\\nThe French press on Monday was filled with questions about why neither President Obama nor Kerry attended Sunday’s march, as about 40 leaders of other nations did. Obama was said to have stayed away because his own security needs can be taxing on a country, and Kerry had prior commitments.\\n\\nAmong roughly 40 leaders who did attend was Israeli Prime Minister Benjamin Netanyahu, no stranger to intense security, who marched beside Hollande through the city streets. The highest ranking U.S. officials attending the march were Jane Hartley, the ambassador to France, and Victoria Nuland, the assistant secretary of state for European affairs. Attorney General Eric H. Holder Jr. was in Paris for meetings with law enforcement officials but did not participate in the march.\\n\\nKerry spent Sunday at a business summit hosted by India’s prime minister, Narendra Modi. The United States is eager for India to relax stringent laws that function as barriers to foreign investment and hopes Modi’s government will act to open the huge Indian market for more American businesses.\\n\\nIn a news conference, Kerry brushed aside criticism that the United States had not sent a more senior official to Paris as “quibbling a little bit.” He noted that many staffers of the American Embassy in Paris attended the march, including the ambassador. He said he had wanted to be present at the march himself but could not because of his prior commitments in India.\\n\\n“But that is why I am going there on the way home, to make it crystal clear how passionately we feel about the events that have taken place there,” he said.\\n\\n“And I don’t think the people of France have any doubts about America’s understanding of what happened, of our personal sense of loss and our deep commitment to the people of France in this moment of trauma.”'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[2,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "Since some rows have information spread accross different columns, we perform the required transformations in order to obtain the final text in a single column.\n",
    "\n",
    "#### X1 Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Election Day: No Legal Pot In Ohio  Democrats ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Who rode it best? Jesse Jackson mounts up to f...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Black Hawk crashes off Florida  human remains ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Afghanistan: 19 die in air attacks on hospital...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Al Qaeda rep says group directed Paris magazin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                concat label\n",
       "192  Election Day: No Legal Pot In Ohio  Democrats ...  REAL\n",
       "308  Who rode it best? Jesse Jackson mounts up to f...  FAKE\n",
       "382  Black Hawk crashes off Florida  human remains ...  REAL\n",
       "660  Afghanistan: 19 die in air attacks on hospital...  REAL\n",
       "889  Al Qaeda rep says group directed Paris magazin...  REAL"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_X1 = train.loc[(train['X1'] == 'REAL') | (train['X1'] == 'FAKE')]\n",
    "fixed_X1 = pd.DataFrame(shifted_X1['title'].map(str) + ' ' + shifted_X1['text'].map(str) + ' ' + shifted_X1['label'].map(str), columns=[\"concat\"])\n",
    "fixed_X1['label'] = shifted_X1[\"X1\"]\n",
    "fixed_X1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X2 Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>Planned Parenthood’s lobbying effort  pay rais...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>Chart Of The Day: Since 2009—–Recovery For The...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 concat label\n",
       "2184  Planned Parenthood’s lobbying effort  pay rais...  REAL\n",
       "3537  Chart Of The Day: Since 2009—–Recovery For The...  FAKE"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted_X2 = train.loc[(train['X2'] == 'REAL') | (train['X2'] == 'FAKE')]\n",
    "fixed_X2 = pd.DataFrame(shifted_X2['title'] + ' ' + shifted_X2['text'].map(str) + ' ' + shifted_X2['label'].map(str) + ' ' + shifted_X2['X1'].map(str), columns = ['concat'])\n",
    "fixed_X2['label'] = shifted_X2[\"X2\"]\n",
    "fixed_X2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You Can Smell Hillary’s Fear Daniel Greenfield...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy U....</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Battle of New York: Why This Primary Matte...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              concat label\n",
       "0  You Can Smell Hillary’s Fear Daniel Greenfield...  FAKE\n",
       "1  Watch The Exact Moment Paul Ryan Committed Pol...  FAKE\n",
       "2  Kerry to go to Paris in gesture of sympathy U....  REAL\n",
       "3  Bernie supporters on Twitter erupt in anger ag...  FAKE\n",
       "4  The Battle of New York: Why This Primary Matte...  REAL"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = train.loc[(train['label'] == 'REAL') | (train['label'] == 'FAKE')]\n",
    "fixed_labeled = pd.DataFrame(labeled['title'].map(str) + ' ' + labeled['text'].map(str), columns = ['concat'])\n",
    "fixed_labeled['label'] = labeled[\"label\"]\n",
    "fixed_labeled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenated Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cc = pd.concat([fixed_X1, fixed_X2, fixed_labeled], axis=0)\n",
    "train_cc[\"concat\"] = train_cc[\"concat\"].str.replace(',', '')\n",
    "train_cc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Election Day: No Legal Pot In Ohio  Democrats ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Who rode it best? Jesse Jackson mounts up to f...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Black Hawk crashes off Florida  human remains ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Afghanistan: 19 die in air attacks on hospital...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Al Qaeda rep says group directed Paris magazin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                concat label\n",
       "192  Election Day: No Legal Pot In Ohio  Democrats ...  REAL\n",
       "308  Who rode it best? Jesse Jackson mounts up to f...  FAKE\n",
       "382  Black Hawk crashes off Florida  human remains ...  REAL\n",
       "660  Afghanistan: 19 die in air attacks on hospital...  REAL\n",
       "889  Al Qaeda rep says group directed Paris magazin...  REAL"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenated Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>September New Homes Sales Rise——-Back To 1992 ...</td>\n",
       "      <td>10498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why The Obamacare Doomsday Cult Can't Admit It...</td>\n",
       "      <td>2439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sanders Cruz resist pressure after NY losses v...</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Surviving escaped prisoner likely fatigued and...</td>\n",
       "      <td>4128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinton and Sanders neck and neck in Californi...</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              concat     ID\n",
       "0  September New Homes Sales Rise——-Back To 1992 ...  10498\n",
       "1  Why The Obamacare Doomsday Cult Can't Admit It...   2439\n",
       "2  Sanders Cruz resist pressure after NY losses v...    864\n",
       "3  Surviving escaped prisoner likely fatigued and...   4128\n",
       "4  Clinton and Sanders neck and neck in Californi...    662"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cc = pd.DataFrame(test['title'].map(str) + ' ' + test['text'].map(str), columns = ['concat'])\n",
    "test_cc[\"concat\"] = test_cc[\"concat\"].str.replace(',', '')\n",
    "test_cc['ID'] = test[\"ID\"]\n",
    "test_cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check target variable balance\n",
    "We review the distribution of values in the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a24c94400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 7))\n",
    "target_count = (train_cc[\"label\"].value_counts() / len(train_cc)) * 100\n",
    "target_count.plot(kind=\"bar\", title=\"Target Distribution (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution is perfect, therefore no resampling is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing data\n",
    "We convert the different articles to a matrix of token counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 56267)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "final_train = count_vect.fit_transform(train_cc.concat)\n",
    "print(final_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized TF/TF-IDF Representation\n",
    "\n",
    "Now we transform the matrix of token counts to a normalized tf or tf-idf representation, where tf represents term frequency and tf-idf represents the frequency times the inverse document frequency, that way the importance/scale of certain repeated tokens throughout the text is reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 56267)\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "final_train = tfidf_transformer.fit_transform(final_train)\n",
    "print(final_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "\n",
    "In order to test the performance of our feature engineering steps, we will create several initial baseline models, that way we will see how our efforts increase the models predictive power.\n",
    "\n",
    "### Train Function\n",
    "Here we define the train function which will be used with the different models, it performs a cross validation score on 80% of the training data and a final validation on the remaining 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, model, grid = None):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=SEED)\n",
    "    \n",
    "    if grid:\n",
    "        model = RandomizedSearchCV(model, grid, cv=5, n_iter=10, refit=True, return_train_score=False, error_score=0.0, n_jobs=-1, random_state=SEED)\n",
    "        model.fit(X_train, y_train)\n",
    "        scores = model.cv_results_[\"mean_test_score\"]\n",
    "    else:\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print(\"Cross validation scores: \\n\" + str(scores))\n",
    "    print(\"Classification Report: \\n\" + str(classification_report(y_test, predictions)))\n",
    "    print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, predictions)))\n",
    "    print(\"Accuracy: \\n\" + str(metric_scorer(y_test, predictions)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: \n",
      "[0.9        0.875      0.8890625  0.86875    0.87323944]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.88      0.91      0.89       421\n",
      "        REAL       0.90      0.85      0.88       379\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       800\n",
      "   macro avg       0.89      0.88      0.89       800\n",
      "weighted avg       0.89      0.89      0.89       800\n",
      "\n",
      "Confusion Matrix: \n",
      "[[385  36]\n",
      " [ 55 324]]\n",
      "Accuracy: \n",
      "0.88625\n"
     ]
    }
   ],
   "source": [
    "X = final_train\n",
    "y = train_cc['label']\n",
    "rf = train(X, y, RandomForestClassifier(n_estimators=100, random_state=SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: \n",
      "[0.725      0.721875   0.7546875  0.7015625  0.72143975]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.98      0.54      0.70       421\n",
      "        REAL       0.66      0.99      0.79       379\n",
      "\n",
      "   micro avg       0.76      0.76      0.76       800\n",
      "   macro avg       0.82      0.77      0.75       800\n",
      "weighted avg       0.83      0.76      0.74       800\n",
      "\n",
      "Confusion Matrix: \n",
      "[[229 192]\n",
      " [  4 375]]\n",
      "Accuracy: \n",
      "0.755\n"
     ]
    }
   ],
   "source": [
    "nb = train(X, y, MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: \n",
      "[0.8953125  0.9078125  0.8890625  0.90625    0.89984351]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.88      0.95      0.91       421\n",
      "        REAL       0.94      0.85      0.90       379\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       800\n",
      "   macro avg       0.91      0.90      0.91       800\n",
      "weighted avg       0.91      0.91      0.91       800\n",
      "\n",
      "Confusion Matrix: \n",
      "[[402  19]\n",
      " [ 56 323]]\n",
      "Accuracy: \n",
      "0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafaelhernandez/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svm = train(X, y, SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Election Day: No Legal Pot In Ohio  Democrats ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Who rode it best? Jesse Jackson mounts up to f...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Black Hawk crashes off Florida  human remains ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Afghanistan: 19 die in air attacks on hospital...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Al Qaeda rep says group directed Paris magazin...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                concat label\n",
       "192  Election Day: No Legal Pot In Ohio  Democrats ...  REAL\n",
       "308  Who rode it best? Jesse Jackson mounts up to f...  FAKE\n",
       "382  Black Hawk crashes off Florida  human remains ...  REAL\n",
       "660  Afghanistan: 19 die in air attacks on hospital...  REAL\n",
       "889  Al Qaeda rep says group directed Paris magazin...  REAL"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation from each word\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')\n",
    "\n",
    "#-----------------------------------------------------\n",
    "\n",
    "import nltk\n",
    "\n",
    "s = \"I can't do this now, because I'm so tired.  Please give me some time. @ sd  4 232\"\n",
    "\n",
    "words = nltk.word_tokenize(s)\n",
    "\n",
    "words=[word.lower() for word in words if word.isalpha()]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Non alphabetic Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove remaining tokens that are not alphabetic\n",
    "# https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
    "# https://stackoverflow.com/questions/15547409/how-to-get-rid-of-punctuation-using-nltk-tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>election day no legal pot in ohio democrats lo...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>who rode best jesse jackson mount fight pipeli...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>black hawk crash florida human remains found c...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>afghanistan die air attack hospital u s invest...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>al qaeda rep say group directed paris magazine...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                concat label\n",
       "192  election day no legal pot in ohio democrats lo...  REAL\n",
       "308  who rode best jesse jackson mount fight pipeli...  FAKE\n",
       "382  black hawk crash florida human remains found c...  REAL\n",
       "660  afghanistan die air attack hospital u s invest...  REAL\n",
       "889  al qaeda rep say group directed paris magazine...  REAL"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train = train_cc.copy()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "#words = stopwords.words(\"english\")\n",
    "final_train['concat'] = final_train['concat'].apply(lambda x:' '.join([lemmatizer.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>elect day legal pot ohio democrat lose south e...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>rode best jess jackson mount fight pipelin leo...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>black hawk crash florida human remain found cn...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>afghanistan die air attack hospit u investig c...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>al qaeda rep say group direct pari magazin att...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                concat label\n",
       "192  elect day legal pot ohio democrat lose south e...  REAL\n",
       "308  rode best jess jackson mount fight pipelin leo...  FAKE\n",
       "382  black hawk crash florida human remain found cn...  REAL\n",
       "660  afghanistan die air attack hospit u investig c...  REAL\n",
       "889  al qaeda rep say group direct pari magazin att...  REAL"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = stopwords.words(\"english\")\n",
    "stemmer = PorterStemmer()\n",
    "#stemmer = SnowballStemmer(language='english') #try both Porter and Snowball\n",
    "final_train['concat'] = final_train['concat'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words])\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: \n",
      "[0.921875   0.934375   0.9375     0.93125    0.94679186]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.95      0.95      0.95       421\n",
      "        REAL       0.94      0.94      0.94       379\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       800\n",
      "   macro avg       0.94      0.94      0.94       800\n",
      "weighted avg       0.94      0.94      0.94       800\n",
      "\n",
      "Confusion Matrix: \n",
      "[[398  23]\n",
      " [ 22 357]]\n",
      "Accuracy: \n",
      "0.94375\n"
     ]
    }
   ],
   "source": [
    "X = final_train['concat']\n",
    "y = final_train['label']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "      ('vect', TfidfVectorizer(min_df= 3, stop_words=\"english\", sublinear_tf=True, norm='l2', ngram_range=(1, 3))),\n",
    "#     ('chi',  SelectKBest(chi2, k=1200)),\n",
    "#     ('rf', RandomForestClassifier()),\n",
    "#     ('nb', MultinomialNB()),\n",
    "      ('pac', PassiveAggressiveClassifier(max_iter=1000, random_state=SEED, tol=1e-3))#,\n",
    "     #('svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=SEED))\n",
    "])\n",
    "\n",
    "# grid = {\n",
    "#     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#     'tfidf__use_idf': [True, False],\n",
    "#     'clf__alpha': [1e-2, 1e-3]\n",
    "# }\n",
    "\n",
    "pipeline = train(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test = test_cc.copy()\n",
    "final_test['concat'] = final_test['concat'].apply(lambda x:' '.join([lemmatizer.lemmatize(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "final_test[\"predictions\"] = pipeline.predict(final_test[\"concat\"])\n",
    "final_test.columns = [\"concat\", \"News_id\", \"prediction\"]\n",
    "final_test[[\"News_id\", \"prediction\"]].to_csv(\"predictions.csv\", index=False)\n",
    "final_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "The classification report obtained from our final model shows its precision (how often the predictions are correct) and the recall (how many of the total observations in the set are correctly classified), also its f1-score (harmonic average of both). The weighted average for all of them stands at 93%, it also has an accuracy of 92.75% which means that it can classify which articles are fake with great efficacy.\n",
    "\n",
    "This information is extremely useful to multiple actors, including social networks and end consumers since it can help them differentiate between real and fake stories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
